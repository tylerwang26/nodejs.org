{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylerwang26/nodejs.org/blob/main/Copy_of_agno_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxS0rTAq5Ubm"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/0x-yuan/clintrial-nlp/blob/main/agno_baseline.ipynb)\n",
        "\n",
        "# å”ä½œæ™ºèƒ½æ€è€ƒæ¡†æ¶åŸºç·š - è‡¨åºŠè©¦é©— NLP\n",
        "\n",
        "## æ¦‚è¿°\n",
        "\n",
        "æœ¬notebookå±•ç¤ºå¦‚ä½•ä½¿ç”¨ç°¡å–®çš„å”ä½œæ€è€ƒæ¨¡å¼é€²è¡Œè‡¨åºŠè©¦é©—è‡ªç„¶èªè¨€æ¨ç†(NLI)ã€‚æˆ‘å€‘æ¨¡æ“¬\"åœ˜éšŠå”ä½œ\"æ¦‚å¿µï¼Œè®“å¤šå€‹å°ˆæ¥­è§’è‰²å”åŒåˆ†æï¼Œæœ€çµ‚é”æˆå…±è­˜ã€‚\n",
        "\n",
        "## ğŸ“š å­¸ç¿’ç›®æ¨™\n",
        "- ç†è§£å”ä½œæ€è€ƒçš„é‡è¦æ€§\n",
        "- å»ºç«‹å°ˆæ¥­è§’è‰²å”ä½œæ¨¡å¼\n",
        "- å¯¦ä½œåœ˜éšŠå…±è­˜æ±ºç­–éç¨‹\n",
        "- è©•ä¼°ç³»çµ±æ•ˆèƒ½\n",
        "\n",
        "### ğŸ¤ å”ä½œæ€è€ƒæ¶æ§‹\n",
        "æˆ‘å€‘å¯¦ä½œ4å€‹å”ä½œè§’è‰²ï¼š\n",
        "1. **è‡¨åºŠç ”ç©¶ä¸»ç®¡**: ç¸½é«”å”èª¿å’Œé†«å­¸å°ˆæ¥­æŒ‡å°\n",
        "2. **è³‡æ–™ç§‘å­¸å®¶**: çµ±è¨ˆåˆ†æå’Œæ•¸æ“šé©—è­‰\n",
        "3. **å“è³ªä¿è­‰å“¡**: é‚è¼¯æª¢æŸ¥å’Œå“è³ªæ§åˆ¶\n",
        "4. **æ±ºç­–å§”å“¡æœƒ**: æ•´åˆæ‰€æœ‰æ„è¦‹ä¸¦é”æˆå…±è­˜\n",
        "\n",
        "> ğŸ’¡ **æ ¸å¿ƒæ¦‚å¿µ**: æ¯å€‹è§’è‰²éƒ½æœ‰ç¨ç‰¹çš„å°ˆæ¥­è¦–è§’ï¼Œé€šéå”ä½œè¨è«–ä¾†æé«˜æ±ºç­–å“è³ªã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9eKJgwv5Ubo",
        "outputId": "16215397-3c3b-4c1f-fdab-f442b2819c8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… æ‰€æœ‰å¥—ä»¶å®‰è£å®Œæˆï¼\n"
          ]
        }
      ],
      "source": [
        "# ğŸ”§ ç’°å¢ƒè¨­ç½® - ä¸€éµå®‰è£æ‰€éœ€å¥—ä»¶\n",
        "!pip install -q google-generativeai python-dotenv pandas tqdm gdown\n",
        "\n",
        "print(\"âœ… æ‰€æœ‰å¥—ä»¶å®‰è£å®Œæˆï¼\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bu4sJrNs5Ubo",
        "outputId": "94fd4f1f-521e-411b-a720-57603125b7d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ å¾ Google Drive ä¸‹è¼‰ clinicaltrial-nlp.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15GA5XI39DDxQ5QkIZXsFbApx1yEvCpcR\n",
            "To: /content/clinicaltrial-nlp.zip\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.47M/5.47M [00:00<00:00, 201MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ æ­£åœ¨è§£å£“ç¸®æª”æ¡ˆ...\n",
            "âœ… è¨“ç·´è³‡æ–™ä¸‹è¼‰ä¸¦è§£å£“ç¸®å®Œæˆï¼\n",
            "ğŸ“„ æ‰¾åˆ° 999 å€‹è‡¨åºŠè©¦é©—JSONæª”æ¡ˆ\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“¥ å¾ Google Drive ä¸‹è¼‰è¨“ç·´è³‡æ–™\n",
        "import os\n",
        "import gdown\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# Google Drive zip æª”æ¡ˆ ID\n",
        "file_id = \"15GA5XI39DDxQ5QkIZXsFbApx1yEvCpcR\"\n",
        "zip_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "zip_filename = \"clinicaltrial-nlp.zip\"\n",
        "\n",
        "if not os.path.exists(\"training_data\"):\n",
        "    print(\"ğŸ“¥ å¾ Google Drive ä¸‹è¼‰ clinicaltrial-nlp.zip...\")\n",
        "    try:\n",
        "        gdown.download(zip_url, zip_filename, quiet=False)\n",
        "\n",
        "        print(\"ğŸ“¦ æ­£åœ¨è§£å£“ç¸®æª”æ¡ˆ...\")\n",
        "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall(\".\")\n",
        "\n",
        "        if os.path.exists(\"clintrial-nlp/training_data\"):\n",
        "            shutil.move(\"clintrial-nlp/training_data\", \"training_data\")\n",
        "            if os.path.exists(\"clintrial-nlp\"):\n",
        "                shutil.rmtree(\"clintrial-nlp\")\n",
        "\n",
        "        os.remove(zip_filename)\n",
        "        print(\"âœ… è¨“ç·´è³‡æ–™ä¸‹è¼‰ä¸¦è§£å£“ç¸®å®Œæˆï¼\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ä¸‹è¼‰å¤±æ•—: {e}\")\n",
        "        print(\"è«‹æ‰‹å‹•ä¸‹è¼‰: https://drive.google.com/file/d/15GA5XI39DDxQ5QkIZXsFbApx1yEvCpcR/view\")\n",
        "else:\n",
        "    print(\"âœ… è¨“ç·´è³‡æ–™å·²å­˜åœ¨ï¼Œè·³éä¸‹è¼‰\")\n",
        "\n",
        "# æª¢æŸ¥ä¸‹è¼‰çš„è³‡æ–™\n",
        "if os.path.exists(\"training_data/CT json\"):\n",
        "    ct_files = len([f for f in os.listdir(\"training_data/CT json\") if f.endswith('.json')])\n",
        "    print(f\"ğŸ“„ æ‰¾åˆ° {ct_files} å€‹è‡¨åºŠè©¦é©—JSONæª”æ¡ˆ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5nqFBse5Ubp",
        "outputId": "035bdef9-9c49-4a37-a7bc-ea65cc67ff3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… å·²å‰µå»ºæ¸¬è©¦è³‡æ–™é›†ï¼ŒåŒ…å« 100 å€‹æ¨£æœ¬\n"
          ]
        }
      ],
      "source": [
        "# ğŸ§ª æº–å‚™æ¸¬è©¦è³‡æ–™é›†\n",
        "import json\n",
        "\n",
        "def create_test_data_if_needed():\n",
        "    if not os.path.exists(\"test.json\"):\n",
        "        try:\n",
        "            with open(\"training_data/train.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "                train_data = json.load(f)\n",
        "            test_data = dict(list(train_data.items())[:100])\n",
        "            with open(\"test.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(test_data, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"âœ… å·²å‰µå»ºæ¸¬è©¦è³‡æ–™é›†ï¼ŒåŒ…å« {len(test_data)} å€‹æ¨£æœ¬\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ å‰µå»ºæ¸¬è©¦è³‡æ–™å¤±æ•—: {e}\")\n",
        "    else:\n",
        "        print(\"âœ… test.json å·²å­˜åœ¨\")\n",
        "\n",
        "create_test_data_if_needed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1ZhQ2Mn5Ubp",
        "outputId": "b24fff45-4861-4b08-feec-684b3f58a22f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ç’°å¢ƒè®Šæ•¸è¼‰å…¥å®Œæˆ\n"
          ]
        }
      ],
      "source": [
        "# è¼‰å…¥ç’°å¢ƒè®Šæ•¸å’Œå¿…è¦å‡½å¼åº«\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import google.generativeai as genai\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "load_dotenv()\n",
        "print(\"âœ… ç’°å¢ƒè®Šæ•¸è¼‰å…¥å®Œæˆ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPM0rv9Z5Ubp"
      },
      "source": [
        "## æ¨¡å‹é…ç½®\n",
        "\n",
        "é…ç½®Google Geminiæ¨¡å‹é€²è¡Œæ¨ç†ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8dD4pDR5Ubp",
        "outputId": "297f3153-bbe9-4326-8463-c836728ad7b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… æ‰¾åˆ° API é‡‘é‘°: AIzaSyDr...-V-4\n",
            "âœ… API é€£æ¥æ¸¬è©¦æˆåŠŸ: API test successful...\n",
            "âœ… Google Geminiæ¨¡å‹é…ç½®å®Œæˆ\n"
          ]
        }
      ],
      "source": [
        "# é…ç½® Google Gemini æ¨¡å‹\n",
        "from google.colab import userdata\n",
        "api_key = os.getenv(\"GEMINI_API_KEY\") or userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    print(\"âš ï¸ è«‹è¨­å®š GOOGLE_API_KEY ç’°å¢ƒè®Šæ•¸\")\n",
        "    print(\"å¯ä»¥åœ¨ Colab å·¦å´é¢æ¿çš„ 'Secrets' ä¸­è¨­å®š\")\n",
        "    raise ValueError(\"ç¼ºå°‘ API é‡‘é‘°\")\n",
        "else:\n",
        "    print(f\"âœ… æ‰¾åˆ° API é‡‘é‘°: {api_key[:8]}...{api_key[-4:]}\")\n",
        "\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# æ¸¬è©¦ API é€£æ¥\n",
        "try:\n",
        "    test_model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "    test_response = test_model.generate_content(\"Hello, respond with 'API test successful'\")\n",
        "    print(f\"âœ… API é€£æ¥æ¸¬è©¦æˆåŠŸ: {test_response.text[:50]}...\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ API é€£æ¥æ¸¬è©¦å¤±æ•—: {e}\")\n",
        "    raise\n",
        "\n",
        "# å‰µå»º Gemini æ¨¡å‹å¯¦ä¾‹\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-2.5-flash\",\n",
        "    generation_config=genai.types.GenerationConfig(\n",
        "        temperature=0.1,\n",
        "        max_output_tokens=4096,\n",
        "        top_p=1,\n",
        "        top_k=1\n",
        "    )\n",
        ")\n",
        "\n",
        "print(f\"âœ… Google Geminiæ¨¡å‹é…ç½®å®Œæˆ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6IJLKxs5Ubp"
      },
      "source": [
        "## è³‡æ–™å·¥å…·å‡½å¼\n",
        "\n",
        "å»ºç«‹ç”¨æ–¼è¼‰å…¥å’Œè™•ç†è‡¨åºŠè©¦é©—è³‡æ–™çš„å·¥å…·å‡½å¼ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WThdifpi5Ubp",
        "outputId": "d65f0689-a282-4c15-f917-e27d1fae9221",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… è³‡æ–™å·¥å…·å‡½å¼æº–å‚™å°±ç·’ã€‚ç¯„ä¾‹è©¦é©—: NCT00066573\n"
          ]
        }
      ],
      "source": [
        "def load_clinical_trial(trial_id: str) -> dict:\n",
        "    \"\"\"è¼‰å…¥è‡¨åºŠè©¦é©—è³‡æ–™\"\"\"\n",
        "    try:\n",
        "        file_path = os.path.join(\"training_data\", \"CT json\", f\"{trial_id}.json\")\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        return {\"error\": f\"æ‰¾ä¸åˆ°è‡¨åºŠè©¦é©— {trial_id}\"}\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"è¼‰å…¥ {trial_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"}\n",
        "\n",
        "def create_collaborative_context(trial_data: dict, focus_section: str = None) -> str:\n",
        "    \"\"\"å‰µå»ºå”ä½œè¨è«–çš„ä¸Šä¸‹æ–‡\"\"\"\n",
        "    if \"error\" in trial_data:\n",
        "        return f\"éŒ¯èª¤: {trial_data['error']}\"\n",
        "\n",
        "    sections = {\n",
        "        \"Eligibility\": trial_data.get(\"Eligibility\", []),\n",
        "        \"Intervention\": trial_data.get(\"Intervention\", []),\n",
        "        \"Results\": trial_data.get(\"Results\", []),\n",
        "        \"Adverse Events\": trial_data.get(\"Adverse_Events\", [])\n",
        "    }\n",
        "\n",
        "    context = [f\"è©¦é©—ç·¨è™Ÿ: {trial_data.get('Clinical Trial ID', 'Unknown')}\"]\n",
        "    context.append(\"\\n=== è©¦é©—è³‡æ–™æ‘˜è¦ ===\")\n",
        "\n",
        "    if focus_section and focus_section in sections:\n",
        "        section_data = sections[focus_section]\n",
        "        context.append(f\"\\n{focus_section} é‡é»è³‡è¨Š:\")\n",
        "        if isinstance(section_data, list):\n",
        "            for i, item in enumerate(section_data[:5]):\n",
        "                context.append(f\"  {i+1}. {item}\")\n",
        "            if len(section_data) > 5:\n",
        "                context.append(f\"  ... (å¦æœ‰ {len(section_data)-5} é …è³‡è¨Š)\")\n",
        "        else:\n",
        "            context.append(f\"  {section_data}\")\n",
        "    else:\n",
        "        for section_name, section_data in sections.items():\n",
        "            if section_data:\n",
        "                context.append(f\"\\n{section_name}:\")\n",
        "                if isinstance(section_data, list):\n",
        "                    for item in section_data[:2]:\n",
        "                        context.append(f\"  â€¢ {item}\")\n",
        "                    if len(section_data) > 2:\n",
        "                        context.append(f\"  â€¢ ... (å…± {len(section_data)} é …)\")\n",
        "                else:\n",
        "                    context.append(f\"  â€¢ {section_data}\")\n",
        "\n",
        "    return \"\\n\".join(context)\n",
        "\n",
        "# æ¸¬è©¦å·¥å…·å‡½å¼\n",
        "sample_trial = load_clinical_trial(\"NCT00066573\")\n",
        "print(f\"âœ… è³‡æ–™å·¥å…·å‡½å¼æº–å‚™å°±ç·’ã€‚ç¯„ä¾‹è©¦é©—: {sample_trial.get('Clinical Trial ID', 'éŒ¯èª¤')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpteMd1Z5Ubp"
      },
      "source": [
        "## å”ä½œè§’è‰²å®šç¾©\n",
        "\n",
        "å®šç¾©å››å€‹å”ä½œè§’è‰²ï¼Œæ¯å€‹è§’è‰²éƒ½æœ‰ç‰¹å®šçš„å°ˆæ¥­è·è²¬ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNDnhs0B5Ubp",
        "outputId": "92ccd32f-4ae1-49b1-d3e9-cf3e4ba4b89b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… å››å€‹å”ä½œè§’è‰²å®šç¾©å®Œæˆ\n"
          ]
        }
      ],
      "source": [
        "def clinical_director_analysis(statement: str, trial_context: str) -> str:\n",
        "    \"\"\"è‡¨åºŠç ”ç©¶ä¸»ç®¡åˆ†æ\"\"\"\n",
        "    prompt = f\"\"\"ä½ æ˜¯è‡¨åºŠç ”ç©¶ä¸»ç®¡ï¼Œè² è²¬å¾æ•´é«”é†«å­¸è§’åº¦å”èª¿åˆ†æã€‚ä½ å…·æœ‰è±å¯Œçš„è‡¨åºŠè©¦é©—ç¶“é©—ã€‚\n",
        "\n",
        "éœ€è¦åˆ†æçš„é™³è¿°: \"{statement}\"\n",
        "\n",
        "è©¦é©—è³‡æ–™:\n",
        "{trial_context}\n",
        "\n",
        "ä½œç‚ºè‡¨åºŠç ”ç©¶ä¸»ç®¡ï¼Œè«‹æä¾›ä½ çš„å°ˆæ¥­åˆ†æï¼š\n",
        "1. å¾é†«å­¸å°ˆæ¥­è§’åº¦è©•ä¼°é™³è¿°çš„åˆç†æ€§\n",
        "2. è€ƒæ…®è‡¨åºŠè©¦é©—çš„æ•´é«”èƒŒæ™¯å’Œè¨­è¨ˆ\n",
        "3. è©•ä¼°é™³è¿°èˆ‡è‡¨åºŠå¯¦å‹™çš„ç›¸ç¬¦ç¨‹åº¦\n",
        "4. æä¾›åˆæ­¥çš„é†«å­¸åˆ¤æ–·\n",
        "\n",
        "è«‹æä¾›ç°¡æ½”çš„åˆ†æï¼Œæœ€å¾Œä»¥ã€Œä¸»ç®¡æ„è¦‹: [æ”¯æŒ/è³ªç–‘/éœ€è¦æ›´å¤šè³‡è¨Š]ã€çµå°¾ã€‚\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"è‡¨åºŠä¸»ç®¡åˆ†æéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def data_scientist_analysis(statement: str, trial_context: str, director_input: str) -> str:\n",
        "    \"\"\"è³‡æ–™ç§‘å­¸å®¶åˆ†æ\"\"\"\n",
        "    prompt = f\"\"\"ä½ æ˜¯è³‡æ–™ç§‘å­¸å®¶ï¼Œå°ˆç²¾çµ±è¨ˆåˆ†æå’Œæ•¸æ“šé©—è­‰ã€‚ä½ å°‡å”åŠ©è‡¨åºŠç ”ç©¶ä¸»ç®¡é€²è¡ŒæŠ€è¡“åˆ†æã€‚\n",
        "\n",
        "éœ€è¦åˆ†æçš„é™³è¿°: \"{statement}\"\n",
        "\n",
        "è©¦é©—è³‡æ–™:\n",
        "{trial_context}\n",
        "\n",
        "è‡¨åºŠä¸»ç®¡çš„æ„è¦‹:\n",
        "{director_input}\n",
        "\n",
        "ä½œç‚ºè³‡æ–™ç§‘å­¸å®¶ï¼Œè«‹å”ä½œåˆ†æï¼š\n",
        "1. é©—è­‰é™³è¿°ä¸­æ¶‰åŠçš„æ•¸å€¼å’Œçµ±è¨ˆè³‡è¨Š\n",
        "2. æª¢æŸ¥è¨ˆç®—çš„æº–ç¢ºæ€§å’Œçµ±è¨ˆæ–¹æ³•\n",
        "3. è©•ä¼°æ•¸æ“šè§£é‡‹æ˜¯å¦æ°ç•¶\n",
        "4. èˆ‡ä¸»ç®¡çš„é†«å­¸è§€é»é€²è¡ŒæŠ€è¡“å°ç…§\n",
        "\n",
        "è«‹æä¾›æŠ€è¡“åˆ†æï¼Œæœ€å¾Œä»¥ã€Œæ•¸æ“šæ„è¦‹: [é©—è­‰é€šé/ç™¼ç¾å•é¡Œ/æ•¸æ“šä¸è¶³]ã€çµå°¾ã€‚\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"è³‡æ–™ç§‘å­¸å®¶åˆ†æéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def quality_assurance_analysis(statement: str, director_input: str, data_input: str) -> str:\n",
        "    \"\"\"å“è³ªä¿è­‰å“¡åˆ†æ\"\"\"\n",
        "    prompt = f\"\"\"ä½ æ˜¯å“è³ªä¿è­‰å“¡ï¼Œè² è²¬é‚è¼¯æª¢æŸ¥å’Œå“è³ªæ§åˆ¶ã€‚ä½ å°‡æ•´åˆåœ˜éšŠçš„ä¸åŒè§€é»ã€‚\n",
        "\n",
        "éœ€è¦åˆ†æçš„é™³è¿°: \"{statement}\"\n",
        "\n",
        "è‡¨åºŠä¸»ç®¡çš„æ„è¦‹:\n",
        "{director_input}\n",
        "\n",
        "è³‡æ–™ç§‘å­¸å®¶çš„æ„è¦‹:\n",
        "{data_input}\n",
        "\n",
        "ä½œç‚ºå“è³ªä¿è­‰å“¡ï¼Œè«‹å”ä½œåˆ†æï¼š\n",
        "1. æª¢æŸ¥é™³è¿°çš„é‚è¼¯ä¸€è‡´æ€§\n",
        "2. é©—è­‰æ¨ç†éç¨‹æ˜¯å¦åˆç†\n",
        "3. è©•ä¼°åœ˜éšŠæ„è¦‹ä¹‹é–“çš„ä¸€è‡´æ€§\n",
        "4. è­˜åˆ¥å¯èƒ½çš„å“è³ªé¢¨éšªæˆ–çŸ›ç›¾\n",
        "\n",
        "è«‹æä¾›å“è³ªæª¢æŸ¥çµæœï¼Œæœ€å¾Œä»¥ã€Œå“è³ªæ„è¦‹: [é€šéæª¢æŸ¥/ç™¼ç¾é¢¨éšª/éœ€è¦æ¾„æ¸…]ã€çµå°¾ã€‚\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"å“è³ªä¿è­‰åˆ†æéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def decision_committee_consensus(statement: str, director_input: str, data_input: str, qa_input: str) -> str:\n",
        "    \"\"\"æ±ºç­–å§”å“¡æœƒå…±è­˜\"\"\"\n",
        "    prompt = f\"\"\"ä½ æ˜¯æ±ºç­–å§”å“¡æœƒä¸»å¸­ï¼Œè² è²¬æ•´åˆæ‰€æœ‰åœ˜éšŠæˆå“¡çš„å°ˆæ¥­æ„è¦‹ï¼Œé”æˆæœ€çµ‚å…±è­˜ã€‚\n",
        "\n",
        "éœ€è¦æ±ºç­–çš„é™³è¿°: \"{statement}\"\n",
        "\n",
        "è‡¨åºŠç ”ç©¶ä¸»ç®¡æ„è¦‹:\n",
        "{director_input}\n",
        "\n",
        "è³‡æ–™ç§‘å­¸å®¶æ„è¦‹:\n",
        "{data_input}\n",
        "\n",
        "å“è³ªä¿è­‰å“¡æ„è¦‹:\n",
        "{qa_input}\n",
        "\n",
        "ä½œç‚ºå§”å“¡æœƒä¸»å¸­ï¼Œè«‹å”èª¿æ‰€æœ‰æ„è¦‹ä¸¦åšå‡ºæœ€çµ‚æ±ºç­–ï¼š\n",
        "1. ç¶œåˆè©•ä¼°å„å°ˆæ¥­è§’åº¦çš„æ„è¦‹\n",
        "2. æ¬Šè¡¡ä¸åŒè§€é»çš„é‡è¦æ€§\n",
        "3. è­˜åˆ¥é—œéµçš„æ±ºç­–å› ç´ \n",
        "4. é”æˆåœ˜éšŠå…±è­˜\n",
        "\n",
        "ä»»å‹™: åˆ¤æ–·é™³è¿°æ˜¯ã€Œè˜Šå«ã€(Entailment)é‚„æ˜¯ã€ŒçŸ›ç›¾ã€(Contradiction)\n",
        "- è˜Šå«: é™³è¿°è¢«è©¦é©—è­‰æ“šæ”¯æŒ\n",
        "- çŸ›ç›¾: é™³è¿°è¢«è©¦é©—è­‰æ“šåé§\n",
        "\n",
        "è«‹æä¾›ç°¡è¦çš„åœ˜éšŠå…±è­˜ç†ç”±ï¼Œç„¶å¾Œä»¥ã€Œå§”å“¡æœƒæ±ºè­°: [Entailment/Contradiction]ã€çµå°¾ã€‚\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"å§”å“¡æœƒæ±ºè­°éŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "print(\"âœ… å››å€‹å”ä½œè§’è‰²å®šç¾©å®Œæˆ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVSX2rPT5Ubq"
      },
      "source": [
        "## å”ä½œæ™ºèƒ½åˆ†æç®¡é“\n",
        "\n",
        "å‰µå»ºå”èª¿æ‰€æœ‰è§’è‰²çš„åœ˜éšŠå”ä½œåˆ†æç®¡é“ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvWSZ3Us5Ubq",
        "outputId": "1db383a8-8820-44ad-d8b0-1669198a987f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… å”ä½œæ™ºèƒ½åˆ†æç®¡é“æº–å‚™å°±ç·’\n"
          ]
        }
      ],
      "source": [
        "def collaborative_intelligence_pipeline(statement: str, primary_id: str, secondary_id: str = None,\n",
        "                                       section_id: str = None, verbose: bool = False) -> str:\n",
        "    \"\"\"é‹è¡Œå®Œæ•´çš„å”ä½œæ™ºèƒ½åˆ†æç®¡é“\"\"\"\n",
        "\n",
        "    try:\n",
        "        # æº–å‚™å”ä½œä¸Šä¸‹æ–‡\n",
        "        primary_data = load_clinical_trial(primary_id)\n",
        "        trial_context = create_collaborative_context(primary_data, section_id)\n",
        "\n",
        "        if secondary_id:\n",
        "            secondary_data = load_clinical_trial(secondary_id)\n",
        "            secondary_context = create_collaborative_context(secondary_data, section_id)\n",
        "            trial_context += f\"\\n\\n=== æ¬¡è¦è©¦é©—è³‡æ–™ ===\\n{secondary_context}\"\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"ğŸ“„ å”ä½œåˆ†æé™³è¿°: {statement[:100]}...\")\n",
        "            print(f\"ğŸ¥ ä¸»è¦è©¦é©—: {primary_id}\")\n",
        "            if secondary_id:\n",
        "                print(f\"ğŸ¥ æ¬¡è¦è©¦é©—: {secondary_id}\")\n",
        "\n",
        "        # ç¬¬ä¸€è¼ª: è‡¨åºŠç ”ç©¶ä¸»ç®¡åˆ†æ\n",
        "        director_analysis = clinical_director_analysis(statement, trial_context)\n",
        "        if verbose:\n",
        "            print(\"ğŸ‘” è‡¨åºŠç ”ç©¶ä¸»ç®¡: å®Œæˆåˆæ­¥åˆ†æ\")\n",
        "\n",
        "        # ç¬¬äºŒè¼ª: è³‡æ–™ç§‘å­¸å®¶å”ä½œåˆ†æ\n",
        "        data_analysis = data_scientist_analysis(statement, trial_context, director_analysis)\n",
        "        if verbose:\n",
        "            print(\"ğŸ“Š è³‡æ–™ç§‘å­¸å®¶: å®ŒæˆæŠ€è¡“é©—è­‰\")\n",
        "\n",
        "        # ç¬¬ä¸‰è¼ª: å“è³ªä¿è­‰å“¡æ•´åˆåˆ†æ\n",
        "        qa_analysis = quality_assurance_analysis(statement, director_analysis, data_analysis)\n",
        "        if verbose:\n",
        "            print(\"ğŸ” å“è³ªä¿è­‰å“¡: å®Œæˆå“è³ªæª¢æŸ¥\")\n",
        "\n",
        "        # ç¬¬å››è¼ª: æ±ºç­–å§”å“¡æœƒé”æˆå…±è­˜\n",
        "        consensus_decision = decision_committee_consensus(\n",
        "            statement, director_analysis, data_analysis, qa_analysis\n",
        "        )\n",
        "\n",
        "        # æå–æœ€çµ‚æ±ºç­–\n",
        "        if \"å§”å“¡æœƒæ±ºè­°: Entailment\" in consensus_decision:\n",
        "            decision = \"Entailment\"\n",
        "        elif \"å§”å“¡æœƒæ±ºè­°: Contradiction\" in consensus_decision:\n",
        "            decision = \"Contradiction\"\n",
        "        else:\n",
        "            # å‚™ç”¨è§£æ\n",
        "            if \"entailment\" in consensus_decision.lower() and \"contradiction\" not in consensus_decision.lower():\n",
        "                decision = \"Entailment\"\n",
        "            else:\n",
        "                decision = \"Contradiction\"\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"ğŸ¤ æ±ºç­–å§”å“¡æœƒ: é”æˆå…±è­˜ - {decision}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        return decision\n",
        "\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"âŒ å”ä½œç®¡é“éŒ¯èª¤: {e}\")\n",
        "        return \"Contradiction\"  # ä¿å®ˆçš„å‚™ç”¨æ–¹æ¡ˆ\n",
        "\n",
        "print(\"âœ… å”ä½œæ™ºèƒ½åˆ†æç®¡é“æº–å‚™å°±ç·’\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SHEOteU5Ubq"
      },
      "source": [
        "## æ¸¬è©¦ç¯„ä¾‹\n",
        "\n",
        "æ¸¬è©¦æˆ‘å€‘çš„å”ä½œæ™ºèƒ½ç³»çµ±ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6AFVzo-5Ubq",
        "outputId": "9b674ce3-0b05-4e52-c14e-ec20b08a9d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ¸¬è©¦å”ä½œæ™ºèƒ½ç³»çµ±:\n",
            "é™³è¿°: 'there is a 13.2% difference between the results from the two the primary trial cohorts'\n",
            "ä¸»è¦è©¦é©—: NCT00066573\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ å”ä½œåˆ†æé™³è¿°: there is a 13.2% difference between the results from the two the primary trial cohorts...\n",
            "ğŸ¥ ä¸»è¦è©¦é©—: NCT00066573\n",
            "ğŸ‘” è‡¨åºŠç ”ç©¶ä¸»ç®¡: å®Œæˆåˆæ­¥åˆ†æ\n",
            "ğŸ“Š è³‡æ–™ç§‘å­¸å®¶: å®ŒæˆæŠ€è¡“é©—è­‰\n",
            "ğŸ” å“è³ªä¿è­‰å“¡: å®Œæˆå“è³ªæª¢æŸ¥\n",
            "ğŸ¤ æ±ºç­–å§”å“¡æœƒ: é”æˆå…±è­˜ - Contradiction\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ¯ å”ä½œæ™ºèƒ½çµæœ: Contradiction\n",
            "â±ï¸ åŸ·è¡Œæ™‚é–“: 71.24 ç§’\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# æ¸¬è©¦ç¯„ä¾‹\n",
        "test_statement = \"there is a 13.2% difference between the results from the two the primary trial cohorts\"\n",
        "test_primary_id = \"NCT00066573\"\n",
        "\n",
        "print(f\"æ¸¬è©¦å”ä½œæ™ºèƒ½ç³»çµ±:\")\n",
        "print(f\"é™³è¿°: '{test_statement}'\")\n",
        "print(f\"ä¸»è¦è©¦é©—: {test_primary_id}\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "# åŸ·è¡Œåˆ†æ\n",
        "start_time = time.time()\n",
        "result = collaborative_intelligence_pipeline(\n",
        "    statement=test_statement,\n",
        "    primary_id=test_primary_id,\n",
        "    section_id=\"Results\",\n",
        "    verbose=True\n",
        ")\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\nğŸ¯ å”ä½œæ™ºèƒ½çµæœ: {result}\")\n",
        "print(f\"â±ï¸ åŸ·è¡Œæ™‚é–“: {end_time - start_time:.2f} ç§’\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrx_UpBl5Ubq"
      },
      "source": [
        "## åœ¨è¨“ç·´è³‡æ–™ä¸Šè©•ä¼°\n",
        "\n",
        "åœ¨è¨“ç·´è³‡æ–™æ¨£æœ¬ä¸Šè©•ä¼°æˆ‘å€‘çš„ç³»çµ±ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4dCHIYB5Ubq",
        "outputId": "3e7ac166-9de6-4fca-bc82-ac8708c9b164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "è¼‰å…¥ 1700 å€‹è¨“ç·´ç¯„ä¾‹\n",
            "\n",
            "åœ¨ 12 å€‹ç¯„ä¾‹ä¸Šè©•ä¼°å”ä½œæ™ºèƒ½ç³»çµ±...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "å”ä½œæ™ºèƒ½è™•ç†:   8%|â–Š         | 1/12 [01:00<11:05, 60.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç¯„ä¾‹  1: Contradiction -> Contradiction âœ… (60.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rå”ä½œæ™ºèƒ½è™•ç†:  17%|â–ˆâ–‹        | 2/12 [02:15<11:30, 69.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç¯„ä¾‹  2: Contradiction -> Contradiction âœ… (75.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rå”ä½œæ™ºèƒ½è™•ç†:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [03:16<09:48, 65.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç¯„ä¾‹  3: Entailment   -> Contradiction âŒ (61.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rå”ä½œæ™ºèƒ½è™•ç†:  33%|â–ˆâ–ˆâ–ˆâ–      | 4/12 [04:21<08:41, 65.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç¯„ä¾‹  4: Contradiction -> Contradiction âœ… (64.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rå”ä½œæ™ºèƒ½è™•ç†:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [05:20<07:20, 62.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç¯„ä¾‹  5: Contradiction -> Contradiction âœ… (59.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rå”ä½œæ™ºèƒ½è™•ç†:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [06:15<06:01, 60.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç¯„ä¾‹  6: Contradiction -> Entailment   âŒ (55.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rå”ä½œæ™ºèƒ½è™•ç†:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [07:02<04:39, 55.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç¯„ä¾‹  7: Contradiction -> Contradiction âœ… (46.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rå”ä½œæ™ºèƒ½è™•ç†:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [07:55<03:39, 54.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç¯„ä¾‹  8: Contradiction -> Contradiction âœ… (52.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rå”ä½œæ™ºèƒ½è™•ç†:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [09:00<02:54, 58.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç¯„ä¾‹  9: Entailment   -> Contradiction âŒ (64.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rå”ä½œæ™ºèƒ½è™•ç†:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 10/12 [09:51<01:52, 56.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç¯„ä¾‹ 10: Contradiction -> Contradiction âœ… (51.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rå”ä½œæ™ºèƒ½è™•ç†:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [10:53<00:57, 57.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç¯„ä¾‹ 11: Entailment   -> Entailment   âœ… (61.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "å”ä½œæ™ºèƒ½è™•ç†: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [11:52<00:00, 59.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç¯„ä¾‹ 12: Entailment   -> Contradiction âŒ (58.7s)\n",
            "\n",
            "ğŸ“Š å”ä½œæ™ºèƒ½ç³»çµ±çµæœ:\n",
            "æº–ç¢ºç‡: 66.67% (8/12)\n",
            "å¹³å‡åŸ·è¡Œæ™‚é–“: 59.35 ç§’/ä¾‹\n",
            "ç¸½åŸ·è¡Œæ™‚é–“: 712.22 ç§’\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# è¼‰å…¥è¨“ç·´è³‡æ–™\n",
        "with open(\"training_data/train.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = json.load(f)\n",
        "print(f\"è¼‰å…¥ {len(train_data)} å€‹è¨“ç·´ç¯„ä¾‹\")\n",
        "\n",
        "# åœ¨æ¨£æœ¬ä¸Šè©•ä¼°\n",
        "sample_size = 12\n",
        "examples = list(train_data.items())[:sample_size]\n",
        "\n",
        "print(f\"\\nåœ¨ {len(examples)} å€‹ç¯„ä¾‹ä¸Šè©•ä¼°å”ä½œæ™ºèƒ½ç³»çµ±...\")\n",
        "\n",
        "results = []\n",
        "correct = 0\n",
        "total_time = 0\n",
        "\n",
        "for i, (uuid, example) in enumerate(tqdm(examples, desc=\"å”ä½œæ™ºèƒ½è™•ç†\")):\n",
        "    try:\n",
        "        statement = example.get(\"Statement\")\n",
        "        primary_id = example.get(\"Primary_id\")\n",
        "        secondary_id = example.get(\"Secondary_id\")\n",
        "        section_id = example.get(\"Section_id\")\n",
        "        expected = example.get(\"Label\")\n",
        "\n",
        "        if not statement or not primary_id:\n",
        "            results.append({\n",
        "                \"uuid\": uuid,\n",
        "                \"expected\": expected,\n",
        "                \"predicted\": \"SKIPPED\",\n",
        "                \"correct\": False,\n",
        "                \"time\": 0\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        # ç²å–é æ¸¬\n",
        "        start_time = time.time()\n",
        "        predicted = collaborative_intelligence_pipeline(\n",
        "            statement=statement,\n",
        "            primary_id=primary_id,\n",
        "            secondary_id=secondary_id,\n",
        "            section_id=section_id,\n",
        "            verbose=False\n",
        "        )\n",
        "        end_time = time.time()\n",
        "\n",
        "        execution_time = end_time - start_time\n",
        "        total_time += execution_time\n",
        "\n",
        "        # æª¢æŸ¥æ­£ç¢ºæ€§\n",
        "        is_correct = (predicted.strip() == expected.strip())\n",
        "        if is_correct:\n",
        "            correct += 1\n",
        "\n",
        "        results.append({\n",
        "            \"uuid\": uuid,\n",
        "            \"statement\": statement[:80] + \"...\" if len(statement) > 80 else statement,\n",
        "            \"expected\": expected,\n",
        "            \"predicted\": predicted,\n",
        "            \"correct\": is_correct,\n",
        "            \"time\": execution_time\n",
        "        })\n",
        "\n",
        "        status = \"âœ…\" if is_correct else \"âŒ\"\n",
        "        print(f\"ç¯„ä¾‹ {i+1:2d}: {expected:12} -> {predicted:12} {status} ({execution_time:.1f}s)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"è™•ç†ç¯„ä¾‹ {i+1} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        results.append({\n",
        "            \"uuid\": uuid,\n",
        "            \"expected\": expected,\n",
        "            \"predicted\": \"ERROR\",\n",
        "            \"correct\": False,\n",
        "            \"time\": 0\n",
        "        })\n",
        "\n",
        "# è¨ˆç®—æº–ç¢ºç‡\n",
        "accuracy = correct / len(examples) if examples else 0\n",
        "avg_time = total_time / len(examples) if examples else 0\n",
        "\n",
        "print(f\"\\nğŸ“Š å”ä½œæ™ºèƒ½ç³»çµ±çµæœ:\")\n",
        "print(f\"æº–ç¢ºç‡: {accuracy:.2%} ({correct}/{len(examples)})\")\n",
        "print(f\"å¹³å‡åŸ·è¡Œæ™‚é–“: {avg_time:.2f} ç§’/ä¾‹\")\n",
        "print(f\"ç¸½åŸ·è¡Œæ™‚é–“: {total_time:.2f} ç§’\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vx6O0Nw5Ubq"
      },
      "source": [
        "## ç”¢ç”Ÿæäº¤æª”æ¡ˆ\n",
        "\n",
        "ä½¿ç”¨æˆ‘å€‘çš„å”ä½œæ™ºèƒ½ç³»çµ±ç”¢ç”Ÿé æ¸¬çµæœï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4rxYDlD5Ubq",
        "outputId": "2fa51baa-4067-4fdf-81c0-032042d750d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ ç‚º 10 å€‹ç¯„ä¾‹ç”¢ç”Ÿå”ä½œæ™ºèƒ½é æ¸¬...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "å”ä½œæ™ºèƒ½è™•ç†: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [10:04<00:00, 60.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… å”ä½œæ™ºèƒ½æäº¤æª”æ¡ˆå·²å„²å­˜è‡³ collaborative_intelligence_submission.json\n",
            "ç‚º 10 å€‹ç¯„ä¾‹ç”¢ç”Ÿäº†é æ¸¬\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def generate_collaborative_submission(test_file=\"test.json\", output_file=\"collaborative_intelligence_submission.json\", sample_size=None):\n",
        "    \"\"\"ä½¿ç”¨å”ä½œæ™ºèƒ½ç³»çµ±ç”¢ç”Ÿæäº¤æª”æ¡ˆ\"\"\"\n",
        "\n",
        "    # è¼‰å…¥æ¸¬è©¦è³‡æ–™\n",
        "    try:\n",
        "        with open(test_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            test_data = json.load(f)\n",
        "    except:\n",
        "        print(f\"âŒ ç„¡æ³•è¼‰å…¥æ¸¬è©¦è³‡æ–™ {test_file}\")\n",
        "        return\n",
        "\n",
        "    examples = list(test_data.items())\n",
        "    if sample_size:\n",
        "        examples = examples[:sample_size]\n",
        "\n",
        "    print(f\"ğŸš€ ç‚º {len(examples)} å€‹ç¯„ä¾‹ç”¢ç”Ÿå”ä½œæ™ºèƒ½é æ¸¬...\")\n",
        "\n",
        "    submission = {}\n",
        "\n",
        "    for i, (uuid, example) in enumerate(tqdm(examples, desc=\"å”ä½œæ™ºèƒ½è™•ç†\")):\n",
        "        try:\n",
        "            statement = example.get(\"Statement\")\n",
        "            primary_id = example.get(\"Primary_id\")\n",
        "            secondary_id = example.get(\"Secondary_id\")\n",
        "            section_id = example.get(\"Section_id\")\n",
        "\n",
        "            if not statement or not primary_id:\n",
        "                submission[uuid] = {\"Prediction\": \"Contradiction\"}\n",
        "                continue\n",
        "\n",
        "            # ç²å–é æ¸¬\n",
        "            prediction = collaborative_intelligence_pipeline(\n",
        "                statement=statement,\n",
        "                primary_id=primary_id,\n",
        "                secondary_id=secondary_id,\n",
        "                section_id=section_id,\n",
        "                verbose=False\n",
        "            )\n",
        "\n",
        "            submission[uuid] = {\"Prediction\": prediction}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"è™•ç† {uuid} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            submission[uuid] = {\"Prediction\": \"Contradiction\"}\n",
        "\n",
        "    # å„²å­˜æäº¤æª”æ¡ˆ\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(submission, f, indent=2)\n",
        "\n",
        "    print(f\"âœ… å”ä½œæ™ºèƒ½æäº¤æª”æ¡ˆå·²å„²å­˜è‡³ {output_file}\")\n",
        "    return submission\n",
        "\n",
        "# ç”¢ç”Ÿå°æ¨£æœ¬æäº¤\n",
        "collaborative_submission = generate_collaborative_submission(\n",
        "    test_file=\"test.json\",\n",
        "    output_file=\"collaborative_intelligence_submission.json\",\n",
        "    sample_size=10\n",
        ")\n",
        "\n",
        "print(f\"ç‚º {len(collaborative_submission)} å€‹ç¯„ä¾‹ç”¢ç”Ÿäº†é æ¸¬\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-774Qmq5Ubq"
      },
      "source": [
        "## çµè«–\n",
        "\n",
        "### å”ä½œæ™ºèƒ½ç³»çµ±å„ªå‹¢ï¼š\n",
        "1. **åœ˜éšŠå”ä½œ**: æ¨¡æ“¬çœŸå¯¦çš„å°ˆæ¥­åœ˜éšŠæ±ºç­–éç¨‹\n",
        "2. **å¤šé‡è¦–è§’**: å¾é†«å­¸ã€æŠ€è¡“ã€å“è³ªç­‰ä¸åŒè§’åº¦åˆ†æ\n",
        "3. **å…±è­˜æ±ºç­–**: é€šéå”å•†é”æˆå¹³è¡¡çš„åˆ¤æ–·\n",
        "4. **å°ˆæ¥­åˆ†å·¥**: æ¯å€‹è§’è‰²éƒ½æœ‰æ˜ç¢ºçš„è·è²¬ç¯„åœ\n",
        "5. **å“è³ªä¿è­‰**: å…§å»ºçš„æª¢æŸ¥å’Œé©—è­‰æ©Ÿåˆ¶\n",
        "\n",
        "### å››è§’è‰²å”ä½œæ¶æ§‹ï¼š\n",
        "- **è‡¨åºŠç ”ç©¶ä¸»ç®¡**: æä¾›é†«å­¸å°ˆæ¥­æŒ‡å°å’Œæ•´é«”å”èª¿\n",
        "- **è³‡æ–™ç§‘å­¸å®¶**: é€²è¡ŒæŠ€è¡“é©—è­‰å’Œçµ±è¨ˆåˆ†æ\n",
        "- **å“è³ªä¿è­‰å“¡**: åŸ·è¡Œé‚è¼¯æª¢æŸ¥å’Œå“è³ªæ§åˆ¶\n",
        "- **æ±ºç­–å§”å“¡æœƒ**: æ•´åˆæ‰€æœ‰æ„è¦‹ä¸¦é”æˆæœ€çµ‚å…±è­˜\n",
        "\n",
        "### å”ä½œæµç¨‹ç‰¹è‰²ï¼š\n",
        "- **é †åºå”ä½œ**: æ¯å€‹è§’è‰²å»ºç«‹åœ¨å‰é¢çš„åˆ†æåŸºç¤ä¸Š\n",
        "- **äº¤å‰é©—è­‰**: ä¸åŒå°ˆæ¥­è¦–è§’çš„ç›¸äº’å°è­‰\n",
        "- **å…±è­˜æ©Ÿåˆ¶**: æœ€çµ‚æ±ºç­–åæ˜ åœ˜éšŠé›†é«”æ™ºæ…§\n",
        "- **å“è³ªæŠŠé—œ**: å¤šå±¤æ¬¡çš„æª¢æŸ¥ç¢ºä¿çµæœå¯é æ€§\n",
        "\n",
        "### é©ç”¨å ´æ™¯ï¼š\n",
        "- éœ€è¦å¤šå°ˆæ¥­å”ä½œçš„è¤‡é›œæ±ºç­–\n",
        "- è¦æ±‚é«˜å¯é æ€§çš„è‡¨åºŠåˆ†æ\n",
        "- åœ˜éšŠæ±ºç­–æµç¨‹çš„æ¨¡æ“¬\n",
        "- éœ€è¦é€æ˜åŒ–æ±ºç­–éç¨‹çš„æ‡‰ç”¨\n",
        "\n",
        "é€™å€‹å”ä½œæ™ºèƒ½ç³»çµ±å±•ç¤ºäº†å¦‚ä½•é€šéæ¨¡æ“¬å°ˆæ¥­åœ˜éšŠçš„å”ä½œæ¨¡å¼ä¾†æé«˜è‡¨åºŠè©¦é©—NLPåˆ†æçš„å“è³ªå’Œå¯é æ€§ï¼Œæ¯å€‹è§’è‰²éƒ½è²¢ç»å…¶å°ˆæ¥­å„ªå‹¢ï¼Œæœ€çµ‚é”æˆåœ˜éšŠå…±è­˜ã€‚"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}